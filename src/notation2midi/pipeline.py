"""This module enables the user to create a 'pipeline', which is a list of actions
that should be performed sequentially.
e.g. :  1. Read and process soundfiles
        2. Create frequency spectra
        3. Determine partials
        4. Create and plot a dissonance graph
Most Actions produce output that can be used by subsequent actions in the pipeline.
Before running a sequence, the PipeLine class checks its validity by determining whether
the input that is required in each step is available from previous steps. The required
input for each step can consist of multiple values or objects.
The application mostly uses Pydantic object structures to pass the data from one
step to the other. The output of intermediate steps can be saved to JSON files and retrieved
later. This enables to read and use this data at the start of a pipeline instead of
re-running the steps that were used to generate this data.
"""

from enum import Enum
from typing import Any, Optional

from pydantic import BaseModel

from src.common.logger import Logging

logger = Logging.get_logger(__name__)


# @dataclass
class Action:
    """
    This class defines actions that correspond with each step of a pipeline (see class Step below).
    Args:
    method (callable): The function that should be called.
    expected_input: (dict[str, Enum | BaseModel], optional) dict containing {keyword: type} combinations
            representing arguments for the function. This parameter should only be used to determine which
            output from previous steps in the pipeline should be passed to the function.
            The value of `expected_input` will be passed as **kwargs during the execution of the pipeline,
            whereby the type indicator will be replaced with the actual output of a previous step.
            Function arguments of which the value is known in advance (e.g. a file name) should be
            defined with the `parameters` argument.
    parameters: Function parameters of which the value is known in advance. E.g. a file name or a requested
            number of
    output: the output type of the function.
    paramters: additional parameters for the method that can be defined before executing the pipeline.
    The values `expected_input` and `output` will be used to perform a validity check before running the pipeline.
    Currently, these values are restricted to Enum and Pydantic BaseModel types, but this is not strictly necessary.
    """

    name: str
    method: callable
    expected_input: Optional[dict[str, Enum | BaseModel]]  # field(default_factory=lambda: dict())
    output: Optional[type] = None
    parameters: Optional[dict[str, Any]]  # field(default_factory=lambda: dict())

    def __init__(
        self,
        *,
        name,
        method,
        parameters: dict[str, Any] = None,
        expected_input: dict[str, Any] = None,
        output: dict[str, Any] = None,
    ):
        # The parameters are assigned by the pipeline and nead to be made unique
        self.expected_input = dict()
        self.parameters = dict()
        self.name = name
        self.method = method
        self.parameters.update(parameters)
        self.expected_input.update(expected_input)
        self.output = output

    def params(self, p):
        # Updates/overwrites the parameters of the action.
        self.parameters.update(p)
        return self

    def __get_data_items__(self, piped_data: dict[str, BaseModel]):
        """Select the necessary input from the data available in the pipeline

        Args:
            piped_data (dict[str, BaseModel]): Data that was generated by previous steps.
        """
        return {keyword: piped_data[datatype] for keyword, datatype in self.expected_input.items()}

    def run(self, piped_data: dict[str, BaseModel]):
        input = self.__get_data_items__(piped_data)
        return self.method(**input, **self.parameters)


class Step(Enum):
    """
    All possible steps that can be combined in a pipeline, with associated action.
    """

    CREATE_INSTRUMENT_GROUP = {
        "method": step_create_group_from_info_file,
        "expected_input": {"groupname": InstrumentGroupName},
        "output": InstrumentGroup,
    }

    def action(self):
        return Action(name=self.name, **self.value)


class PipeLine:
    """
    The pipeline enables to execute a sequence of functions that generate output for subsequent
    functions. The sequence is determined in the `pipe` parameter.
    Currently, only data of types InstrumentGroupName, InstrumentGroup or AggregatedPartialDict
    Can be passed from one function to the other.
    Additional pre-set parameters can be set through the Step objects in the Step class definition.
    These parameters can later be overuled by calling the `param` method of a Step object.

    Returns:
        PipeLine: A PipeLine object.
    """

    groupname: InstrumentGroupName = None
    pipe: list[Action] = None  # list of actions that should be performed sequentially
    data: dict[str, BaseModel] = dict()  # dict to which results of piped actions will be added

    def __init__(self, groupname: InstrumentGroupName, pipe: list[Step]):
        """
        Args:
            groupname (InstrumentGroupName): The instrument group. The first step action will receive this value
                                             as input and should not expect any other input.
            pipe (Pipe): A list of Step values which defines the sequence in which actions should be performed.
            Warning: Illegal sequence if the sequence of the Pipe object is infeasible. This is the case
                     if an action expects input that is not created by any preceding step.
        """
        self.data[InstrumentGroupName] = groupname
        self.pipe = pipe

        if not self.is_valid_pipe(pipe):
            logger.error("Aborting script.")
            exit()

    def is_valid_pipe(self, pipe: list[Step]) -> bool:
        available_data = {item.__class__ for item in self.data.values()}
        action: Action
        for action in pipe:
            if not all([item in available_data for item in action.expected_input.values()]):
                logger.error(f"Invalid pipeline sequence: not all input is available for step {action.name}.")
                return False
            if action.output:
                available_data.add(action.output)
        return True

    def __get_data_items__(self, datatypes: dict[str, type]):
        return {keyword: self.data[datatype] for keyword, datatype in datatypes.items()}

    def execute(self):
        logger.info(f"STARTING PIPELINE FOR {self.data[InstrumentGroupName].value.upper()}")
        action: Action
        for action in self.pipe:
            logger.info(f"STEP {action.name}")
            # inputdict = self.__get_data_items__(action.expected_input)
            result = action.run(self.data)
            self.data[type(result)] = result


# FULL SEQUENCE STARTS HERE
PIPE_NEW_GROUP_PROCESS_AND_PLOT_AUDIO_NO_CLIPFIX = [
    Step.CREATE_INSTRUMENT_GROUP.action(),
]

if __name__ == "__main__":
    pipes = [
        # PIPE_NEW_GROUP_PROCESS_AND_PLOT_AUDIO_NO_CLIPFIX,
        # PIPE_CREATE_NOTE_SPECTRA,
        # PIPE_CREATE_PARTIALS_AND_SAVE,
        # PIPE_AGGREGATE_PARTIALS_AND_SAVE,
        PIPE_PLOT_NOTE_SPECTRA,
    ]
    for pipe in pipes:
        pipeline = PipeLine(InstrumentGroupName.ANGKLUNG, pipe)
        pipeline.execute()
